######
# Generated by mxnet.export, do not edit by hand.
######

#' Take absolute value of the src
#' 
#' @param src  NDArray
#'     Source input to the function
#' @return out The result mx.ndarray
#' 
#' @export
#' @name mx.nd.abs
NULL

#' Take argmax indices of each channel of the src.The result will be ndarray of shape (num_channel,) on the same device.
#' 
#' @param src  NDArray
#'     Source input to the function
#' @return out The result mx.ndarray
#' 
#' @export
#' @name mx.nd.argmax.channel
NULL

#' Calculate batched dot product of two matrices. (batch, M, K) batch_dot (batch, K, N) --> (batch, M, N)
#' 
#' @param lhs  NDArray
#'     Left operand  to the function
#' @param rhs  NDArray
#'     Right operand to the function
#' @return out The result mx.ndarray
#' 
#' @export
#' @name mx.nd.batch.dot
NULL

#' Broadcast data in the given axis to the given size. The original size of the broadcasting axis must be 1.
#' 
#' @param src  NDArray
#'     Source input to the function
#' @param axis  Shape(tuple), optional, default=()
#'     The axes to perform the broadcasting.
#' @param size  Shape(tuple), optional, default=()
#'     Target sizes of the broadcasting axes.
#' @return out The result mx.ndarray
#' 
#' @export
#' @name mx.nd.broadcast.axis
NULL

#' lhs divide rhs with broadcast
#' 
#' @param lhs  NDArray
#'     Left operand  to the function
#' @param rhs  NDArray
#'     Right operand to the function
#' @return out The result mx.ndarray
#' 
#' @export
#' @name mx.nd.broadcast.div
NULL

#' lhs minus rhs with broadcast
#' 
#' @param lhs  NDArray
#'     Left operand  to the function
#' @param rhs  NDArray
#'     Right operand to the function
#' @return out The result mx.ndarray
#' 
#' @export
#' @name mx.nd.broadcast.minus
NULL

#' lhs multiple rhs with broadcast
#' 
#' @param lhs  NDArray
#'     Left operand  to the function
#' @param rhs  NDArray
#'     Right operand to the function
#' @return out The result mx.ndarray
#' 
#' @export
#' @name mx.nd.broadcast.mul
NULL

#' lhs add rhs with broadcast
#' 
#' @param lhs  NDArray
#'     Left operand  to the function
#' @param rhs  NDArray
#'     Right operand to the function
#' @return out The result mx.ndarray
#' 
#' @export
#' @name mx.nd.broadcast.plus
NULL

#' lhs power rhs with broadcast
#' 
#' @param lhs  NDArray
#'     Left operand  to the function
#' @param rhs  NDArray
#'     Right operand to the function
#' @return out The result mx.ndarray
#' 
#' @export
#' @name mx.nd.broadcast.power
NULL

#' Broadcast data to the target shape. The original size of the broadcasting axis must be 1.
#' 
#' @param src  NDArray
#'     Source input to the function
#' @param shape  Shape(tuple), optional, default=()
#'     The shape of the desired array. We can set the dim to zero if it's same as the original. E.g `A = broadcast_to(B, shape=(10, 0, 0))` has the same meaning as `A = broadcast_axis(B, axis=0, size=10)`.
#' @return out The result mx.ndarray
#' 
#' @export
#' @name mx.nd.broadcast.to
NULL

#' Take ceil value of the src
#' 
#' @param src  NDArray
#'     Source input to the function
#' @return out The result mx.ndarray
#' 
#' @export
#' @name mx.nd.ceil
NULL

#' Choose one element from each line(row for python, column for R/Julia) in lhs according to index indicated by rhs. This function assume rhs uses 0-based index.
#' 
#' @param lhs  NDArray
#'     Left operand to the function.
#' @param rhs  NDArray
#'     Right operand to the function.
#' @return out The result mx.ndarray
#' 
#' @export
#' @name mx.nd.choose.element.0index
NULL

#' Clip ndarray elements to range (a_min, a_max)
#' 
#' @param src  NDArray
#'     Source input
#' @param a.min  real_t
#'     Minimum value
#' @param a.max  real_t
#'     Maximum value
#' @return out The result mx.ndarray
#' 
#' @export
#' @name mx.nd.clip
NULL

#' Take cos of the src
#' 
#' @param src  NDArray
#'     Source input to the function
#' @return out The result mx.ndarray
#' 
#' @export
#' @name mx.nd.cos
NULL

#' Crop the input matrix and return a new one
#' 
#' @param src  NDArray
#'     Source input to the function
#' @param begin  Shape(tuple), required
#'     starting coordinates
#' @param end  Shape(tuple), required
#'     ending coordinates
#' @return out The result mx.ndarray
#' 
#' @export
#' @name mx.nd.crop
NULL

#' Calculate dot product of two matrices or two vectors
#' 
#' @param lhs  NDArray
#'     Left operand  to the function
#' @param rhs  NDArray
#'     Right operand to the function
#' @return out The result mx.ndarray
#' 
#' @export
#' @name mx.nd.dot
NULL

#' Take exp of the src
#' 
#' @param src  NDArray
#'     Source input to the function
#' @return out The result mx.ndarray
#' 
#' @export
#' @name mx.nd.exp
NULL

#' Expand the shape of array by inserting a new axis.
#' 
#' @param src  NDArray
#'     Source input to the function
#' @param axis  int (non-negative), required
#'     Position (amongst axes) where new axis is to be inserted.
#' @return out The result mx.ndarray
#' 
#' @export
#' @name mx.nd.expand.dims
NULL

#' Fill one element of each line(row for python, column for R/Julia) in lhs according to index indicated by rhs and values indicated by mhs. This function assume rhs uses 0-based index.
#' 
#' @param lhs  NDArray
#'     Left operand to the function.
#' @param mhs  NDArray
#'     Middle operand to the function.
#' @param rhs  NDArray
#'     Right operand to the function.
#' @return out The result mx.ndarray
#' 
#' @export
#' @name mx.nd.fill.element.0index
NULL

#' Flip the input matrix along axis and return a new one
#' 
#' @param src  NDArray
#'     Source input to the function
#' @param axis  int, required
#'     The dimension to flip
#' @return out The result mx.ndarray
#' 
#' @export
#' @name mx.nd.flip
NULL

#' Take floor value of the src
#' 
#' @param src  NDArray
#'     Source input to the function
#' @return out The result mx.ndarray
#' 
#' @export
#' @name mx.nd.floor
NULL

#' Take log of the src
#' 
#' @param src  NDArray
#'     Source input to the function
#' @return out The result mx.ndarray
#' 
#' @export
#' @name mx.nd.log
NULL

#' Take max of the src in the given axis and returns a NDArray. Follows numpy semantics.
#' 
#' @param src  NDArray
#'     Source input to the function
#' @param axis  Shape(tuple), optional, default=()
#'     Same as Numpy. The axes to perform the reduction.If left empty, a global reduction will be performed.
#' @param keepdims  boolean, optional, default=False
#'     Same as Numpy. If keepdims is set to true, the axis which is reduced is left in the result as dimension with size one.
#' @return out The result mx.ndarray
#' 
#' @export
#' @name mx.nd.max
NULL

#' (Depreciated! Use max instead!) Take max of the src in the given axis and returns a NDArray. Follows numpy semantics.
#' 
#' @param src  NDArray
#'     Source input to the function
#' @param axis  Shape(tuple), optional, default=()
#'     Same as Numpy. The axes to perform the reduction.If left empty, a global reduction will be performed.
#' @param keepdims  boolean, optional, default=False
#'     Same as Numpy. If keepdims is set to true, the axis which is reduced is left in the result as dimension with size one.
#' @return out The result mx.ndarray
#' 
#' @export
#' @name mx.nd.max.axis
NULL

#' Take min of the src in the given axis and returns a NDArray. Follows numpy semantics.
#' 
#' @param src  NDArray
#'     Source input to the function
#' @param axis  Shape(tuple), optional, default=()
#'     Same as Numpy. The axes to perform the reduction.If left empty, a global reduction will be performed.
#' @param keepdims  boolean, optional, default=False
#'     Same as Numpy. If keepdims is set to true, the axis which is reduced is left in the result as dimension with size one.
#' @return out The result mx.ndarray
#' 
#' @export
#' @name mx.nd.min
NULL

#' (Depreciated! Use min instead!) Take min of the src in the given axis and returns a NDArray. Follows numpy semantics.
#' 
#' @param src  NDArray
#'     Source input to the function
#' @param axis  Shape(tuple), optional, default=()
#'     Same as Numpy. The axes to perform the reduction.If left empty, a global reduction will be performed.
#' @param keepdims  boolean, optional, default=False
#'     Same as Numpy. If keepdims is set to true, the axis which is reduced is left in the result as dimension with size one.
#' @return out The result mx.ndarray
#' 
#' @export
#' @name mx.nd.min.axis
NULL

#' Take L2 norm of the src.The result will be ndarray of shape (1,) on the same device.
#' 
#' @param src  NDArray
#'     Source input to the function
#' @return out The result mx.ndarray
#' 
#' @export
#' @name mx.nd.norm
NULL

#' Take round value of the src
#' 
#' @param src  NDArray
#'     Source input to the function
#' @return out The result mx.ndarray
#' 
#' @export
#' @name mx.nd.round
NULL

#' Take rsqrt of the src
#' 
#' @param src  NDArray
#'     Source input to the function
#' @return out The result mx.ndarray
#' 
#' @export
#' @name mx.nd.rsqrt
NULL

#' Take sign value of the src
#' 
#' @param src  NDArray
#'     Source input to the function
#' @return out The result mx.ndarray
#' 
#' @export
#' @name mx.nd.sign
NULL

#' Take sin of the src
#' 
#' @param src  NDArray
#'     Source input to the function
#' @return out The result mx.ndarray
#' 
#' @export
#' @name mx.nd.sin
NULL

#' Slice the input along certain axis and return a sliced array.
#' 
#' @param src  NDArray
#'     Source input to the function
#' @param axis  int, required
#'     The axis to be sliced
#' @param begin  int, required
#'     The beginning index to be sliced
#' @param end  int, required
#'     The end index to be sliced
#' @return out The result mx.ndarray
#' 
#' @export
#' @name mx.nd.slice.axis
NULL

#' Calculate Smooth L1 Loss(lhs, scalar)
#' 
#' @param src  NDArray
#'     Source input to the function
#' @return out The result mx.ndarray
#' 
#' @export
#' @name mx.nd.smooth.l1
NULL

#' Calculate cross_entropy(lhs, one_hot(rhs))
#' 
#' @param lhs  NDArray
#'     Left operand  to the function
#' @param rhs  NDArray
#'     Right operand to the function
#' @return out The result mx.ndarray
#' 
#' @export
#' @name mx.nd.softmax.cross.entropy
NULL

#' Take sqrt of the src
#' 
#' @param src  NDArray
#'     Source input to the function
#' @return out The result mx.ndarray
#' 
#' @export
#' @name mx.nd.sqrt
NULL

#' Take square of the src
#' 
#' @param src  NDArray
#'     Source input to the function
#' @return out The result mx.ndarray
#' 
#' @export
#' @name mx.nd.square
NULL

#' Take sum of the src in the given axis and returns a NDArray. Follows numpy semantics.
#' 
#' @param src  NDArray
#'     Source input to the function
#' @param axis  Shape(tuple), optional, default=()
#'     Same as Numpy. The axes to perform the reduction.If left empty, a global reduction will be performed.
#' @param keepdims  boolean, optional, default=False
#'     Same as Numpy. If keepdims is set to true, the axis which is reduced is left in the result as dimension with size one.
#' @return out The result mx.ndarray
#' 
#' @export
#' @name mx.nd.sum
NULL

#' (Depreciated! Use sum instead!) Take sum of the src in the given axis and returns a NDArray. Follows numpy semantics.
#' 
#' @param src  NDArray
#'     Source input to the function
#' @param axis  Shape(tuple), optional, default=()
#'     Same as Numpy. The axes to perform the reduction.If left empty, a global reduction will be performed.
#' @param keepdims  boolean, optional, default=False
#'     Same as Numpy. If keepdims is set to true, the axis which is reduced is left in the result as dimension with size one.
#' @return out The result mx.ndarray
#' 
#' @export
#' @name mx.nd.sum.axis
NULL

#' Transpose the input matrix and return a new one
#' 
#' @param src  NDArray
#'     Source input to the function
#' @param axes  Shape(tuple), optional, default=()
#'     Target axis order. By default the axes will be inverted.
#' @return out The result mx.ndarray
#' 
#' @export
#' @name mx.nd.transpose
NULL

#' Create iterator for dataset in csv.
#' 
#' @param data.csv  string, required
#'     Dataset Param: Data csv path.
#' @param data.shape  Shape(tuple), required
#'     Dataset Param: Shape of the data.
#' @param label.csv  string, optional, default='NULL'
#'     Dataset Param: Label csv path. If is NULL, all labels will be returned as 0
#' @param label.shape  Shape(tuple), optional, default=(1,)
#'     Dataset Param: Shape of the label.
#' @return iter The result mx.dataiter
#' 
#' @export
mx.io.CSVIter <- function(...) {
  mx.varg.io.CSVIter(list(...))
}

#' Create iterator for dataset packed in recordio.
#' 
#' @param path.imglist  string, optional, default=''
#'     Dataset Param: Path to image list.
#' @param path.imgrec  string, optional, default='./data/imgrec.rec'
#'     Dataset Param: Path to image record file.
#' @param aug.seq  string, optional, default='aug_default'
#'     Augmentation Param: the augmenter names to represent sequence of augmenters to be applied, seperated by comma. Additional keyword parameters will be seen by these augmenters.
#' @param label.width  int, optional, default='1'
#'     Dataset Param: How many labels for an image.
#' @param data.shape  Shape(tuple), required
#'     Dataset Param: Shape of each instance generated by the DataIter.
#' @param preprocess.threads  int, optional, default='4'
#'     Backend Param: Number of thread to do preprocessing.
#' @param verbose  boolean, optional, default=True
#'     Auxiliary Param: Whether to output parser information.
#' @param num.parts  int, optional, default='1'
#'     partition the data into multiple parts
#' @param part.index  int, optional, default='0'
#'     the index of the part will read
#' @param shuffle  boolean, optional, default=False
#'     Augmentation Param: Whether to shuffle data.
#' @param seed  int, optional, default='0'
#'     Augmentation Param: Random Seed.
#' @param batch.size  int (non-negative), required
#'     Batch Param: Batch size.
#' @param round.batch  boolean, optional, default=True
#'     Batch Param: Use round robin to handle overflow batch.
#' @param prefetch.buffer  , optional, default=4
#'     Backend Param: Number of prefetched parameters
#' @param rand.crop  boolean, optional, default=False
#'     Augmentation Param: Whether to random crop on the image
#' @param crop.y.start  int, optional, default='-1'
#'     Augmentation Param: Where to nonrandom crop on y.
#' @param crop.x.start  int, optional, default='-1'
#'     Augmentation Param: Where to nonrandom crop on x.
#' @param max.rotate.angle  int, optional, default='0'
#'     Augmentation Param: rotated randomly in [-max_rotate_angle, max_rotate_angle].
#' @param max.aspect.ratio  float, optional, default=0
#'     Augmentation Param: denotes the max ratio of random aspect ratio augmentation.
#' @param max.shear.ratio  float, optional, default=0
#'     Augmentation Param: denotes the max random shearing ratio.
#' @param max.crop.size  int, optional, default='-1'
#'     Augmentation Param: Maximum crop size.
#' @param min.crop.size  int, optional, default='-1'
#'     Augmentation Param: Minimum crop size.
#' @param max.random.scale  float, optional, default=1
#'     Augmentation Param: Maxmum scale ratio.
#' @param min.random.scale  float, optional, default=1
#'     Augmentation Param: Minimum scale ratio.
#' @param max.img.size  float, optional, default=1e+10
#'     Augmentation Param: Maxmum image size after resizing.
#' @param min.img.size  float, optional, default=0
#'     Augmentation Param: Minimum image size after resizing.
#' @param random.h  int, optional, default='0'
#'     Augmentation Param: Maximum value of H channel in HSL color space.
#' @param random.s  int, optional, default='0'
#'     Augmentation Param: Maximum value of S channel in HSL color space.
#' @param random.l  int, optional, default='0'
#'     Augmentation Param: Maximum value of L channel in HSL color space.
#' @param rotate  int, optional, default='-1'
#'     Augmentation Param: Rotate angle.
#' @param fill.value  int, optional, default='255'
#'     Augmentation Param: Maximum value of illumination variation.
#' @param data.shape  Shape(tuple), required
#'     Dataset Param: Shape of each instance generated by the DataIter.
#' @param inter.method  int, optional, default='1'
#'     Augmentation Param: 0-NN 1-bilinear 2-cubic 3-area 4-lanczos4 9-auto 10-rand.
#' @param pad  int, optional, default='0'
#'     Augmentation Param: Padding size.
#' @param mirror  boolean, optional, default=False
#'     Augmentation Param: Whether to mirror the image.
#' @param rand.mirror  boolean, optional, default=False
#'     Augmentation Param: Whether to mirror the image randomly.
#' @param mean.img  string, optional, default=''
#'     Augmentation Param: Mean Image to be subtracted.
#' @param mean.r  float, optional, default=0
#'     Augmentation Param: Mean value on R channel.
#' @param mean.g  float, optional, default=0
#'     Augmentation Param: Mean value on G channel.
#' @param mean.b  float, optional, default=0
#'     Augmentation Param: Mean value on B channel.
#' @param mean.a  float, optional, default=0
#'     Augmentation Param: Mean value on Alpha channel.
#' @param scale  float, optional, default=1
#'     Augmentation Param: Scale in color space.
#' @param max.random.contrast  float, optional, default=0
#'     Augmentation Param: Maximum ratio of contrast variation.
#' @param max.random.illumination  float, optional, default=0
#'     Augmentation Param: Maximum value of illumination variation.
#' @return iter The result mx.dataiter
#' 
#' @export
mx.io.ImageRecordIter <- function(...) {
  mx.varg.io.ImageRecordIter(list(...))
}

#' Create iterator for MNIST hand-written digit number recognition dataset.
#' 
#' @param image  string, optional, default='./train-images-idx3-ubyte'
#'     Dataset Param: Mnist image path.
#' @param label  string, optional, default='./train-labels-idx1-ubyte'
#'     Dataset Param: Mnist label path.
#' @param batch.size  int, optional, default='128'
#'     Batch Param: Batch Size.
#' @param shuffle  boolean, optional, default=True
#'     Augmentation Param: Whether to shuffle data.
#' @param flat  boolean, optional, default=False
#'     Augmentation Param: Whether to flat the data into 1D.
#' @param seed  int, optional, default='0'
#'     Augmentation Param: Random Seed.
#' @param silent  boolean, optional, default=False
#'     Auxiliary Param: Whether to print out data info.
#' @param num.parts  int, optional, default='1'
#'     partition the data into multiple parts
#' @param part.index  int, optional, default='0'
#'     the index of the part will read
#' @param prefetch.buffer  , optional, default=4
#'     Backend Param: Number of prefetched parameters
#' @return iter The result mx.dataiter
#' 
#' @export
mx.io.MNISTIter <- function(...) {
  mx.varg.io.MNISTIter(list(...))
}

#' Apply activation function to input.Softmax Activation is only available with CUDNN on GPUand will be computed at each location across channel if input is 4D.
#' 
#' @param data  Symbol
#'     Input data to activation function.
#' @param act.type  {'relu', 'sigmoid', 'softrelu', 'tanh'}, required
#'     Activation function to be applied.
#' @param name  string, optional
#'     Name of the resulting symbol.
#' @return out The result mx.symbol
#' 
#' @export
mx.symbol.Activation <- function(...) {
  mx.varg.symbol.Activation(list(...))
}

#' Apply batch normalization to input.
#' 
#' @param data  Symbol
#'     Input data to batch normalization
#' @param eps  float, optional, default=0.001
#'     Epsilon to prevent div 0
#' @param momentum  float, optional, default=0.9
#'     Momentum for moving average
#' @param fix.gamma  boolean, optional, default=True
#'     Fix gamma while training
#' @param use.global.stats  boolean, optional, default=False
#'     Whether use global moving statistics instead of local batch-norm. This will force change batch-norm into a scale shift operator.
#' @param name  string, optional
#'     Name of the resulting symbol.
#' @return out The result mx.symbol
#' 
#' @export
mx.symbol.BatchNorm <- function(...) {
  mx.varg.symbol.BatchNorm(list(...))
}

#' Get output from a symbol and pass 0 gradient back
#' 
#' @param data  Symbol
#'     Input data.
#' @param name  string, optional
#'     Name of the resulting symbol.
#' @return out The result mx.symbol
#' 
#' @export
mx.symbol.BlockGrad <- function(...) {
  mx.varg.symbol.BlockGrad(list(...))
}

#' Cast array to a different data type.
#' 
#' @param data  Symbol
#'     Input data to cast function.
#' @param dtype  {'float16', 'float32', 'float64', 'int32', 'uint8'}, required
#'     Target data type.
#' @param name  string, optional
#'     Name of the resulting symbol.
#' @return out The result mx.symbol
#' 
#' @export
mx.symbol.Cast <- function(...) {
  mx.varg.symbol.Cast(list(...))
}

#' Apply convolution to input then add a bias.
#' 
#' @param data  Symbol
#'     Input data to the ConvolutionOp.
#' @param weight  Symbol
#'     Weight matrix.
#' @param bias  Symbol
#'     Bias parameter.
#' @param kernel  Shape(tuple), required
#'     convolution kernel size: (y, x)
#' @param stride  Shape(tuple), optional, default=(1,1)
#'     convolution stride: (y, x)
#' @param dilate  Shape(tuple), optional, default=(1,1)
#'     convolution dilate: (y, x)
#' @param pad  Shape(tuple), optional, default=(0,0)
#'     pad for convolution: (y, x)
#' @param num.filter  int (non-negative), required
#'     convolution filter(channel) number
#' @param num.group  int (non-negative), optional, default=1
#'     Number of groups partition. This option is not supported by CuDNN, you can use SliceChannel to num_group,apply convolution and concat instead to achieve the same need.
#' @param workspace  long (non-negative), optional, default=512
#'     Tmp workspace for convolution (MB).
#' @param no.bias  boolean, optional, default=False
#'     Whether to disable bias parameter.
#' @param cudnn.tune  {'fastest', 'limited_workspace', 'off'},optional, default='limited_workspace'
#'     Whether to find convolution algo by running performance test.Leads to higher startup time but may give better speed
#' @param name  string, optional
#'     Name of the resulting symbol.
#' @return out The result mx.symbol
#' 
#' @export
mx.symbol.Convolution <- function(...) {
  mx.varg.symbol.Convolution(list(...))
}

#' Crop the 2nd and 3rd dim of input data, with the corresponding size of h_w or with width and height of the second input symbol, i.e., with one input, we need h_w to specify the crop height and width, otherwise the second input symbol's size will be used
#' 
#' @param data  Symbol or Symbol[]
#'     Tensor or List of Tensors, the second input will be used as crop_like shape reference
#' @param num.args  int, required
#'     Number of inputs for crop, if equals one, then we will use the h_wfor crop height and width, else if equals two, then we will use the heightand width of the second input symbol, we name crop_like here
#' @param offset  Shape(tuple), optional, default=(0,0)
#'     crop offset coordinate: (y, x)
#' @param h.w  Shape(tuple), optional, default=(0,0)
#'     crop height and weight: (h, w)
#' @param center.crop  boolean, optional, default=False
#'     If set to true, then it will use be the center_crop,or it will crop using the shape of crop_like
#' @param name  string, optional
#'     Name of the resulting symbol.
#' @return out The result mx.symbol
#' 
#' @export
mx.symbol.Crop <- function(...) {
  mx.varg.symbol.Crop(list(...))
}

#' Custom operator implemented in frontend.
#' 
#' @param op.type  string
#'     Type of custom operator. Must be registered first.
#' @param name  string, optional
#'     Name of the resulting symbol.
#' @return out The result mx.symbol
#' 
#' @export
mx.symbol.Custom <- function(...) {
  mx.varg.symbol.Custom(list(...))
}

#' Apply deconvolution to input then add a bias.
#' 
#' @param data  Symbol
#'     Input data to the DeconvolutionOp.
#' @param weight  Symbol
#'     Weight matrix.
#' @param bias  Symbol
#'     Bias parameter.
#' @param kernel  Shape(tuple), required
#'     deconvolution kernel size: (y, x)
#' @param stride  Shape(tuple), optional, default=(1,1)
#'     deconvolution stride: (y, x)
#' @param pad  Shape(tuple), optional, default=(0,0)
#'     pad for deconvolution: (y, x), a good number is : (kernel-1)/2, if target_shape set, pad will be ignored and will be computed automatically
#' @param adj  Shape(tuple), optional, default=(0,0)
#'     adjustment for output shape: (y, x), if target_shape set, adj will be ignored and will be computed automatically
#' @param target.shape  Shape(tuple), optional, default=(0,0)
#'     output shape with targe shape : (y, x)
#' @param num.filter  int (non-negative), required
#'     deconvolution filter(channel) number
#' @param num.group  int (non-negative), optional, default=1
#'     number of groups partition
#' @param workspace  long (non-negative), optional, default=512
#'     Tmp workspace for deconvolution (MB)
#' @param no.bias  boolean, optional, default=True
#'     Whether to disable bias parameter.
#' @param name  string, optional
#'     Name of the resulting symbol.
#' @return out The result mx.symbol
#' 
#' @export
mx.symbol.Deconvolution <- function(...) {
  mx.varg.symbol.Deconvolution(list(...))
}

#' Apply dropout to input
#' 
#' @param data  Symbol
#'     Input data to dropout.
#' @param p  float, optional, default=0.5
#'     Fraction of the input that gets dropped out at training time
#' @param name  string, optional
#'     Name of the resulting symbol.
#' @return out The result mx.symbol
#' 
#' @export
mx.symbol.Dropout <- function(...) {
  mx.varg.symbol.Dropout(list(...))
}

#' Perform an elementwise sum over all the inputs.
#' 
#' @param num.args  int, required
#'     Number of inputs to be summed.
#' @param name  string, optional
#'     Name of the resulting symbol.
#' @return out The result mx.symbol
#' 
#' @export
mx.symbol.ElementWiseSum <- function(...) {
  mx.varg.symbol.ElementWiseSum(list(...))
}

#' Get embedding for one-hot input. A n-dimensional input tensor will be trainsformed into a (n+1)-dimensional tensor, where a new dimension is added for the embedding results.
#' 
#' @param data  Symbol
#'     Input data to the EmbeddingOp.
#' @param weight  Symbol
#'     Enbedding weight matrix.
#' @param input.dim  int, required
#'     input dim of one-hot encoding
#' @param output.dim  int, required
#'     output dim of embedding
#' @param name  string, optional
#'     Name of the resulting symbol.
#' @return out The result mx.symbol
#' 
#' @export
mx.symbol.Embedding <- function(...) {
  mx.varg.symbol.Embedding(list(...))
}

#' Flatten input
#' 
#' @param data  Symbol
#'     Input data to flatten.
#' @param name  string, optional
#'     Name of the resulting symbol.
#' @return out The result mx.symbol
#' 
#' @export
mx.symbol.Flatten <- function(...) {
  mx.varg.symbol.Flatten(list(...))
}

#' Apply matrix multiplication to input then add a bias.
#' 
#' @param data  Symbol
#'     Input data to the FullyConnectedOp.
#' @param weight  Symbol
#'     Weight matr